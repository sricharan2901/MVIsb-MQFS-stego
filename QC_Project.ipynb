{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv2fOdWRCw52"
      },
      "source": [
        "## Attempting Base Paper Implementation: MVI-MQFS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JA-SrjkCtbH",
        "outputId": "3fe857af-7891-4c15-e126-684c53549363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install qiskit qiskit_aer --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiGTxW3eShDc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from qiskit import QuantumCircuit, transpile\n",
        "from qiskit_aer import AerSimulator\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNTi5w8lSj_j"
      },
      "outputs": [],
      "source": [
        "def text_to_bits(text):\n",
        "    \"\"\"Convert text to a string of bits.\"\"\"\n",
        "    return ''.join(format(ord(char), '08b') for char in text)\n",
        "\n",
        "def bits_to_text(bits):\n",
        "    \"\"\"Convert a string of bits back to text.\"\"\"\n",
        "    padding = 8 - (len(bits) % 8)\n",
        "    if padding != 8:\n",
        "        bits = \"0\" * padding + bits\n",
        "\n",
        "    chars = [bits[i:i+8] for i in range(0, len(bits), 8)]\n",
        "    text = \"\"\n",
        "    for char_bits in chars:\n",
        "        if int(char_bits, 2) != 0:\n",
        "            text += chr(int(char_bits, 2))\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QazQ-RaSnh8"
      },
      "outputs": [],
      "source": [
        "def image_to_bitstream(image_path):\n",
        "    \"\"\"Load an image and convert it into a flat bitstream.\"\"\"\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image_array = np.array(image)\n",
        "    return ''.join(format(val, '08b') for val in image_array.flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "981D80YuSpRe"
      },
      "outputs": [],
      "source": [
        "def bitstream_to_image(bitstream, image_path, output_path):\n",
        "    \"\"\"Convert a bitstream back into an image of the same dimensions as a template.\"\"\"\n",
        "    template_image = Image.open(image_path).convert('RGB')\n",
        "    width, height = template_image.size\n",
        "\n",
        "    num_values = width * height * 3\n",
        "    expected_bits = num_values * 8\n",
        "\n",
        "    if len(bitstream) > expected_bits:\n",
        "        bitstream = bitstream[:expected_bits]\n",
        "    elif len(bitstream) < expected_bits:\n",
        "        bitstream += '0' * (expected_bits - len(bitstream))\n",
        "\n",
        "    pixel_values = [int(bitstream[i:i+8], 2) for i in range(0, expected_bits, 8)]\n",
        "    image_array = np.array(pixel_values, dtype=np.uint8).reshape((height, width, 3))\n",
        "    stego_image = Image.fromarray(image_array)\n",
        "    stego_image.save(output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c005Ynd5Stb2"
      },
      "outputs": [],
      "source": [
        "def quantum_xor_operation(bit1, bit2):\n",
        "    \"\"\"\n",
        "    Performs a symmetric and deterministic quantum XOR (CX) operation.\n",
        "    This is used for both embedding (stego = host XOR secret)\n",
        "    and extraction (secret = stego XOR host).\n",
        "    \"\"\"\n",
        "    qc = QuantumCircuit(2, 1)\n",
        "\n",
        "    if bit1 == '1':\n",
        "        qc.x(0)\n",
        "    if bit2 == '1':\n",
        "        qc.x(1)\n",
        "\n",
        "    qc.cx(1, 0)\n",
        "\n",
        "    qc.measure(0, 0)\n",
        "\n",
        "    simulator = AerSimulator()\n",
        "    compiled_circuit = transpile(qc, simulator)\n",
        "    result = simulator.run(compiled_circuit, shots=1, memory=True).result()\n",
        "    output_bit = result.get_memory()[0]\n",
        "\n",
        "    return output_bit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAk_wKOPS4ce"
      },
      "outputs": [],
      "source": [
        "def encrypt_with_qiskit(image_path, secret_message, modulo_value, output_path):\n",
        "    \"\"\"\n",
        "    Encrypts a message into an image using the MVI-MQFS conceptual model.\n",
        "    \"\"\"\n",
        "    print(\"--- Starting Encryption ---\")\n",
        "\n",
        "    image_bits = list(image_to_bitstream(image_path))\n",
        "    secret_bits = text_to_bits(secret_message)\n",
        "\n",
        "    msg_len_bits = format(len(secret_bits), '032b')\n",
        "    for i in range(32):\n",
        "        image_bits[i] = msg_len_bits[i]\n",
        "\n",
        "    print(f\"Embedding {len(secret_bits)} bits of secret data...\")\n",
        "\n",
        "    for i in range(len(secret_bits)):\n",
        "        position = 32 + (i * modulo_value)\n",
        "\n",
        "        if position >= len(image_bits):\n",
        "            raise ValueError(\"Message is too long or modulo value is too large for this image.\")\n",
        "\n",
        "        host_bit = image_bits[position]\n",
        "        secret_bit = secret_bits[i]\n",
        "\n",
        "        stego_bit = quantum_xor_operation(host_bit, secret_bit)\n",
        "\n",
        "        image_bits[position] = stego_bit\n",
        "\n",
        "        if (i+1) % 50 == 0:\n",
        "            print(f\"  ...embedded bit {i+1}/{len(secret_bits)}\")\n",
        "\n",
        "    bitstream_to_image(\"\".join(image_bits), image_path, output_path)\n",
        "    print(f\"Encryption complete. Stego image saved to '{output_path}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joqim2hOS1PE"
      },
      "outputs": [],
      "source": [
        "def decrypt_with_qiskit(stego_image_path, original_cover_path, modulo_value):\n",
        "    \"\"\"\n",
        "    Decrypts a message from an image using the non-blind MVI-MQFS model.\n",
        "    Requires the original cover image for comparison.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Starting Decryption ---\")\n",
        "\n",
        "    stego_bits = image_to_bitstream(stego_image_path)\n",
        "    original_bits = image_to_bitstream(original_cover_path)\n",
        "\n",
        "    msg_len_bits = stego_bits[:32]\n",
        "    msg_len = int(msg_len_bits, 2)\n",
        "\n",
        "    print(f\"Expecting a message of {msg_len} bits...\")\n",
        "\n",
        "    extracted_secret_bits = \"\"\n",
        "    for i in range(msg_len):\n",
        "        position = 32 + (i * modulo_value)\n",
        "\n",
        "        if position >= len(stego_bits):\n",
        "            raise ValueError(\"Image is not large enough to contain the encoded message length.\")\n",
        "\n",
        "        stego_bit = stego_bits[position]\n",
        "        host_bit = original_bits[position]\n",
        "\n",
        "        secret_bit = quantum_xor_operation(stego_bit, host_bit)\n",
        "\n",
        "        extracted_secret_bits += secret_bit\n",
        "\n",
        "        if (i+1) % 50 == 0:\n",
        "            print(f\"  ...extracted bit {i+1}/{msg_len}\")\n",
        "\n",
        "    secret_message = bits_to_text(extracted_secret_bits)\n",
        "    print(f\"Decryption complete.\")\n",
        "    return secret_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SuHVL0rCXnc",
        "outputId": "eb1dc16a-e3e7-46fa-a276-e685827bfc48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Encryption ---\n",
            "Embedding 504 bits of secret data...\n",
            "  ...embedded bit 50/504\n",
            "  ...embedded bit 100/504\n",
            "  ...embedded bit 150/504\n",
            "  ...embedded bit 200/504\n",
            "  ...embedded bit 250/504\n",
            "  ...embedded bit 300/504\n",
            "  ...embedded bit 350/504\n",
            "  ...embedded bit 400/504\n",
            "  ...embedded bit 450/504\n",
            "  ...embedded bit 500/504\n",
            "Encryption complete. Stego image saved to 'stego_image_qiskit.png'\n",
            "\n",
            "--- Starting Decryption ---\n",
            "Expecting a message of 504 bits...\n",
            "  ...extracted bit 50/504\n",
            "  ...extracted bit 100/504\n",
            "  ...extracted bit 150/504\n",
            "  ...extracted bit 200/504\n",
            "  ...extracted bit 250/504\n",
            "  ...extracted bit 300/504\n",
            "  ...extracted bit 350/504\n",
            "  ...extracted bit 400/504\n",
            "  ...extracted bit 450/504\n",
            "  ...extracted bit 500/504\n",
            "Decryption complete.\n",
            "\n",
            "--- Verification ---\n",
            "Original Message:  This is a secret test of the Qisk-it MVI-MQFS conceptual model!\n",
            "Decrypted Message: This is a secret test of the Qisk-it MVI-MQFS conceptual model!\n",
            "\n",
            "Success! The message was recovered correctly.\n"
          ]
        }
      ],
      "source": [
        "COVER_IMAGE = \"cover_image.png\"\n",
        "STEGO_IMAGE = \"stego_image_qiskit.png\"\n",
        "SECRET_MESSAGE = \"This is a secret test of the Qisk-it MVI-MQFS conceptual model!\"\n",
        "\n",
        "MODULO_VALUE = 313\n",
        "encrypt_with_qiskit(COVER_IMAGE, SECRET_MESSAGE, MODULO_VALUE, STEGO_IMAGE)\n",
        "\n",
        "decrypted_message = decrypt_with_qiskit(STEGO_IMAGE, COVER_IMAGE, MODULO_VALUE)\n",
        "\n",
        "print(\"\\n--- Verification ---\")\n",
        "print(\"Original Message: \", SECRET_MESSAGE)\n",
        "print(\"Decrypted Message:\", decrypted_message)\n",
        "\n",
        "if SECRET_MESSAGE == decrypted_message:\n",
        "    print(\"\\nSuccess! The message was recovered correctly.\")\n",
        "else:\n",
        "    print(\"\\nFailure. The message was not recovered correctly.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 911
        },
        "id": "T_-cU1P39uCO",
        "outputId": "b24a291a-1a59-454c-8fb7-e18fcc383ff9"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "COVER_IMAGE = \"/content/cover_image.png\"\n",
        "STEGO_IMAGE = \"/content/stego_image_qiskit.png\"\n",
        "\n",
        "print(\"Cover Image:\")\n",
        "cover_image = Image.open(COVER_IMAGE)\n",
        "display(cover_image)\n",
        "\n",
        "print(\"\\nStego Image:\")\n",
        "stego_image = Image.open(STEGO_IMAGE)\n",
        "display(stego_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_Vc3OWzTIUq"
      },
      "source": [
        "## Novelty Attempt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHFBrEGJTKq_"
      },
      "outputs": [],
      "source": [
        "!pip install numpy pillow qiskit qiskit-aer torch torchvision opencv-python --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11arWBRlWfiu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from qiskit import QuantumCircuit, transpile\n",
        "from qiskit_aer import AerSimulator\n",
        "import cv2\n",
        "\n",
        "PROCESSING_SIZE = (384, 384)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAcy0W9uWo7F"
      },
      "outputs": [],
      "source": [
        "def text_to_bits(text):\n",
        "    \"\"\"Convert text to a string of bits.\"\"\"\n",
        "    return ''.join(format(ord(char), '08b') for char in text)\n",
        "\n",
        "def bits_to_text(bits):\n",
        "    \"\"\"Convert a string of bits back to text.\"\"\"\n",
        "    padding = 8 - (len(bits) % 8)\n",
        "    if padding != 8: bits = \"0\" * padding + bits\n",
        "    chars = [bits[i:i+8] for i in range(0, len(bits), 8)]\n",
        "    text = \"\"\n",
        "    for char_bits in chars:\n",
        "        if int(char_bits, 2) != 0: text += chr(int(char_bits, 2))\n",
        "    return text\n",
        "\n",
        "def quantum_xor_operation(bit1, bit2):\n",
        "    \"\"\"Performs a deterministic quantum XOR (CX) operation.\"\"\"\n",
        "    qc = QuantumCircuit(2, 1)\n",
        "    if bit1 == '1': qc.x(0)\n",
        "    if bit2 == '1': qc.x(1)\n",
        "    qc.cx(1, 0)\n",
        "    qc.measure(0, 0)\n",
        "    simulator = AerSimulator()\n",
        "    compiled_circuit = transpile(qc, simulator)\n",
        "    result = simulator.run(compiled_circuit, shots=1, memory=True).result()\n",
        "    return result.get_memory()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kKMnbNvWmBY"
      },
      "outputs": [],
      "source": [
        "def get_salience_map(image, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Generates a salience map from a pre-resized PIL image.\n",
        "    The output mask will have the same dimensions as the input image.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        model = torch.hub.load(\"intel-isl/MiDaS\", \"MiDaS_small\", trust_repo=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load AI model. Please check internet connection. Error: {e}\")\n",
        "        return None\n",
        "    model.to('cpu')\n",
        "    model.eval()\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    input_batch = transform(image).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = model(input_batch)\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "            prediction.unsqueeze(1),\n",
        "            size=image.size[::-1],\n",
        "            mode=\"bicubic\", align_corners=False,\n",
        "        ).squeeze()\n",
        "\n",
        "    depth_map = prediction.cpu().numpy()\n",
        "    normalized_map = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min())\n",
        "    binary_mask = (normalized_map < threshold).astype(np.uint8)\n",
        "\n",
        "    print(f\"Salience map generated with dimensions: {binary_mask.shape}\")\n",
        "    return binary_mask.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McByXRwL-nQz"
      },
      "outputs": [],
      "source": [
        "def get_salience_map(image_path, threshold=0.5, alpha=0.4):\n",
        "    \"\"\"\n",
        "    Uses a pre-trained model to generate a salience map and saves a visual overlay.\n",
        "    This version GUARANTEES the output mask matches the input image dimensions\n",
        "    and also saves a highlighted visualization image.\n",
        "    \"\"\"\n",
        "    print(\"--- 1. Generating Classical Salience Map ---\")\n",
        "    try:\n",
        "        model = torch.hub.load(\"intel-isl/MiDaS\", \"MiDaS_small\", trust_repo=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load AI model. Please check internet connection. Error: {e}\")\n",
        "        return None\n",
        "    model.to('cpu')\n",
        "    model.eval()\n",
        "\n",
        "    input_image_path = \"./cover_image.png\"\n",
        "    input_image = Image.open(input_image_path).convert('RGB')\n",
        "    original_size_wh = input_image.size\n",
        "    original_size_hw = (input_image.height, input_image.width)\n",
        "\n",
        "    processed_image = input_image.resize(PROCESSING_SIZE, Image.Resampling.LANCZOS)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    input_batch = transform(processed_image).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = model(input_batch)\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "            prediction.unsqueeze(1),\n",
        "            size=original_size_hw,\n",
        "            mode=\"bicubic\", align_corners=False,\n",
        "        ).squeeze()\n",
        "\n",
        "\n",
        "    depth_map = prediction.cpu().numpy()\n",
        "    normalized_map = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min())\n",
        "\n",
        "    saliency_map_resized = normalized_map\n",
        "\n",
        "    if saliency_map_resized.shape != original_size_hw:\n",
        "        print(f\"Warning: Correcting salience map dimension mismatch. Finalizing to {original_size_hw}\")\n",
        "        saliency_map_resized = cv2.resize(saliency_map_resized, original_size_wh, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "\n",
        "    binary_mask = (saliency_map_resized < threshold).astype(np.uint8)\n",
        "    print(f\"Salience map generated with guaranteed dimensions: {binary_mask.shape}\")\n",
        "\n",
        "    overlay_array = np.zeros((original_size_hw[0], original_size_hw[1], 3), dtype=np.uint8)\n",
        "    overlay_array[binary_mask == 1] = [255, 0, 0]\n",
        "    overlay_image = Image.fromarray(overlay_array, 'RGB')\n",
        "\n",
        "    highlighted_image = Image.blend(input_image, overlay_image, alpha=alpha)\n",
        "    highlighted_image.save(\"salience_overlay_visualization.png\")\n",
        "    print(\"Salience overlay visualization saved as 'salience_overlay_visualization.png'\")\n",
        "\n",
        "\n",
        "    return binary_mask.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RqNLrgyXBVq"
      },
      "outputs": [],
      "source": [
        "def encrypt(image_path, secret_message, output_path):\n",
        "\n",
        "    original_image = Image.open(image_path).convert('RGB')\n",
        "    processed_image = original_image.resize(PROCESSING_SIZE, Image.Resampling.LANCZOS)\n",
        "\n",
        "    image_array = np.array(processed_image)\n",
        "    image_bits = list(''.join(format(val, '08b') for val in image_array.flatten()))\n",
        "\n",
        "    safe_pixel_mask = get_salience_map(processed_image)\n",
        "    if safe_pixel_mask is None: return\n",
        "\n",
        "    safe_pixel_indices = np.where(safe_pixel_mask == 1)[0]\n",
        "\n",
        "    available_embedding_indices = []\n",
        "    for pixel_idx in safe_pixel_indices:\n",
        "        available_embedding_indices.extend([pixel_idx * 24 + 7, pixel_idx * 24 + 15, pixel_idx * 24 + 23])\n",
        "\n",
        "    secret_bits = text_to_bits(secret_message)\n",
        "    msg_len_bits = format(len(secret_bits), '032b')\n",
        "    full_secret_bits = msg_len_bits + secret_bits\n",
        "\n",
        "    if len(full_secret_bits) > len(available_embedding_indices):\n",
        "        raise ValueError(f\"Message too long for available safe LSBs. Need {len(full_secret_bits)}, have {len(available_embedding_indices)}.\")\n",
        "\n",
        "    print(f\"\\nEmbedding {len(full_secret_bits)} bits of data into safe LSBs...\")\n",
        "\n",
        "    for i in range(len(full_secret_bits)):\n",
        "        position = available_embedding_indices[i]\n",
        "        host_bit, secret_bit = image_bits[position], full_secret_bits[i]\n",
        "        stego_bit = quantum_xor_operation(host_bit, secret_bit)\n",
        "        image_bits[position] = stego_bit\n",
        "\n",
        "    stego_array = np.array([int(\"\".join(image_bits[i:i+8]), 2) for i in range(0, len(image_bits), 8)], dtype=np.uint8).reshape(image_array.shape)\n",
        "    stego_image = Image.fromarray(stego_array)\n",
        "    stego_image.save(output_path)\n",
        "    print(f\"Encryption complete. Stego image saved to '{output_path}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h11pcRyzXJWs"
      },
      "outputs": [],
      "source": [
        "def decrypt(stego_image_path, original_cover_path):\n",
        "    original_image = Image.open(original_cover_path).convert('RGB')\n",
        "    processed_original = original_image.resize(PROCESSING_SIZE, Image.Resampling.LANCZOS)\n",
        "\n",
        "    stego_image = Image.open(stego_image_path).convert('RGB')\n",
        "    if stego_image.size != PROCESSING_SIZE:\n",
        "        print(f\"Warning: Stego image size is {stego_image.size}, resizing to standard {PROCESSING_SIZE} for decryption.\")\n",
        "        stego_image = stego_image.resize(PROCESSING_SIZE, Image.Resampling.LANCZOS)\n",
        "\n",
        "    stego_bits = ''.join(format(val, '08b') for val in np.array(stego_image).flatten())\n",
        "    original_bits = ''.join(format(val, '08b') for val in np.array(processed_original).flatten())\n",
        "\n",
        "    safe_pixel_mask = get_salience_map(processed_original)\n",
        "    if safe_pixel_mask is None: return\n",
        "\n",
        "    safe_pixel_indices = np.where(safe_pixel_mask == 1)[0]\n",
        "    available_embedding_indices = []\n",
        "    for pixel_idx in safe_pixel_indices:\n",
        "        available_embedding_indices.extend([pixel_idx * 24 + 7, pixel_idx * 24 + 15, pixel_idx * 24 + 23])\n",
        "\n",
        "    msg_len_bits = \"\"\n",
        "    for i in range(32):\n",
        "        position = available_embedding_indices[i]\n",
        "        stego_bit, host_bit = stego_bits[position], original_bits[position]\n",
        "        len_bit = quantum_xor_operation(stego_bit, host_bit)\n",
        "        msg_len_bits += len_bit\n",
        "    msg_len = int(msg_len_bits, 2)\n",
        "    print(f\"Expecting a message of {msg_len} bits...\")\n",
        "\n",
        "    extracted_secret_bits = \"\"\n",
        "    for i in range(msg_len):\n",
        "        position = available_embedding_indices[32 + i]\n",
        "        stego_bit, host_bit = stego_bits[position], original_bits[position]\n",
        "        secret_bit = quantum_xor_operation(stego_bit, host_bit)\n",
        "        extracted_secret_bits += secret_bit\n",
        "\n",
        "    secret_message = bits_to_text(extracted_secret_bits)\n",
        "    print(f\"Decryption complete.\")\n",
        "    return secret_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsZ5ebBgPiQ4",
        "outputId": "99e45f5c-ee74-46f6-dbb2-c6350b07d943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 1. Generating Classical Salience Map ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n",
            "Using cache found in /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading weights:  None\n",
            "Salience map generated with guaranteed dimensions: (2000, 3008)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2869777183.py:53: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  overlay_image = Image.fromarray(overlay_array, 'RGB')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Salience overlay visualization saved as 'salience_overlay_visualization.png'\n",
            "\n",
            "Embedding 640 bits of data into safe LSBs...\n",
            "Encryption complete. Stego image saved to 'stego_image_hybrid.png'\n",
            "--- 1. Generating Classical Salience Map ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n",
            "Using cache found in /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading weights:  None\n",
            "Salience map generated with guaranteed dimensions: (2000, 3008)\n",
            "Salience overlay visualization saved as 'salience_overlay_visualization.png'\n",
            "Expecting a message of 608 bits...\n",
            "Decryption complete.\n",
            "Original Message:   This is the final test for the hybrid classical-quantum steganography model!\n",
            "Decrypted Message:  This is the final test for the hybrid classical-quantum steganography model!\n",
            "\n",
            "The message was recovered correctly.\n"
          ]
        }
      ],
      "source": [
        "COVER_IMAGE = \"cover_image.png\"\n",
        "STEGO_IMAGE = \"stego_image_hybrid.png\"\n",
        "SECRET_MESSAGE = \"This is the final test for the hybrid classical-quantum steganography model!\"\n",
        "\n",
        "encrypt(COVER_IMAGE, SECRET_MESSAGE, STEGO_IMAGE)\n",
        "decrypted_message = decrypt(STEGO_IMAGE, COVER_IMAGE)\n",
        "\n",
        "print(\"Original Message:  \", SECRET_MESSAGE)\n",
        "print(\"Decrypted Message: \", decrypted_message)\n",
        "\n",
        "if SECRET_MESSAGE == decrypted_message:\n",
        "    print(\"\\nThe message was recovered correctly.\")\n",
        "else:\n",
        "    print(\"\\nThe message was not recovered correctly.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JmdNRMrU-1rQ",
        "outputId": "f5d9f33f-5e03-4640-a05f-29721082ffd5"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "COVER_IMAGE = \"/content/cover_image.png\"\n",
        "SALIENCE_IMAGE = \"/content/salience_overlay_visualization.png\"\n",
        "STEGO_IMAGE = \"/content/stego_image_hybrid.png\"\n",
        "\n",
        "print(\"Cover Image:\")\n",
        "cover_image = Image.open(COVER_IMAGE)\n",
        "display(cover_image)\n",
        "\n",
        "print(\"\\nSalience Map:\")\n",
        "salience_image = Image.open(SALIENCE_IMAGE)\n",
        "display(salience_image)\n",
        "\n",
        "print(\"Stego Image:\")\n",
        "stego_image = Image.open(STEGO_IMAGE)\n",
        "display(stego_image)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
